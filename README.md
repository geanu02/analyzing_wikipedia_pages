# Optimizing Code Performance on Large Datasets

We'll be analyzing data web-scraped from Wikipedia pages.

Our main goals will be to:

- Extract only the text from the Wikipedia pages, and remove all HTML and Javascript markup.
- Remove common page headers and footers from the Wikipedia pages.
- Figure out what tags are the most common in Wikipedia pages.
- Figure out patterns in the text.
